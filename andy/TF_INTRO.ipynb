{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TensorFlow(TF) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of tensor and tensorflow \n",
    "in order to understand what is tensorflow we need first to understand what is tensor. in particular, a tensor, put simply, is a n-dimensional matrix. So a 2-dimensional tensor \n",
    "is the same as a standard matrix; we can view a (m x m x m) tensor as a cube array of numbers. from the defition of tensor, the definition of TensorFlow comes as \"an opensource software library for numerical computation using data flow graph\"\n",
    "#### Data flow graphs \n",
    "this is the computational model for TensorFlow where the nodes are functions/computations and the edges are numbers, matrices or tensor \n",
    "![data flow graph](img/data_flow_graphs.png)\n",
    "There are number of reasons this is useful. Fist, many common  machine learning models (Neural Networks) are directed graphs. Second,TF can easily computes derivative of any node and this is the heart of neural network optimization. Finally, this enables distributing across multiple computational devices (GPUs)\n",
    "![title](img/multi_tensor_graphs.png)\n",
    "#### Main components of TF\n",
    "##### TensorFlow \n",
    "this is the API for defining machine learning models, training them with data and exporting them for further use \n",
    "##### TensorBoard \n",
    "this is graph visulization software that is included with any standard TF installation \n",
    "##### TensorFlow Serving \n",
    "this is software that facilitates easy deployment of pre-trained TF models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF - Hello World\n",
    "##### TF Installation\n",
    "The installation will be much less painful and easy for you if you are in linux; just following two steps: \n",
    "1. create a virtual environment (conda or virtul env)\n",
    "2. pip install tensorflow (cpu) or pip install tensorflow-gpu (gpu)\n",
    "\n",
    "if you own a MAC you it is easy to install tensorflow (cpu) but for gpu support you might need to build it from source:\n",
    "--> follow the official guile https://www.tensorflow.org/install/install_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you install TF successfully, you might want to try out these lines of code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random_normal([2,20])\n",
    "sess = tf.Session()\n",
    "out = sess.run(a)\n",
    "x,y = out \n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's go over what the rest of the code does:\n",
    "1. Use TF to create 2x20 matrix of random number and assign it to the variable a \n",
    "2. Start a TF session and assign it to sess \n",
    "3. Execute a with the sess.run() method and assign the output (which is a NumPy array) to out \n",
    "4. Split up the 2x20 matrix into two 1x10 vectors, x and y \n",
    "5. Use pyplot to create a scatter plot with x and y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fundamental TensorFlow Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph basics \n",
    "At the core of every TensorFlow program is the computation graph described in code\n",
    "with the TensorFlow API. A computation graph, is a specific type of directed graph that is\n",
    "used for defining, unsurprisingly, computational structure. In TensorFlow it is, in essence,\n",
    "a series of functions chained together, each passing its output to zero, one, or more\n",
    "functions further along in the chain. In this way, a user can construct a complex\n",
    "transformation on data by using blocks of smaller, well-understood mathematical\n",
    "functions. Let’s take a look at a bare-bones example.\n",
    "![title](img/gb1.png)\n",
    "In the above example, we see the graph for basic addition. The function, represented by\n",
    "a circle, takes in two inputs, represented as arrows pointing into the function. It outputs the\n",
    "result of adding 1 and 2 together: 3, which is shown as an arrow pointing out of the\n",
    "function. The result could then be passed along to another function, or it might simply be\n",
    "returned to the client.\n",
    "We can also look at this graph as a simple equation:\n",
    "The above illustrates how the two fundamental building blocks of graphs, nodes and\n",
    "edges, are used when constructing a computation graph. Let’s go over their properties:\n",
    "Nodes, typically drawn as circles, ovals, or boxes, represent some sort of\n",
    "computation or action being done on or with data in the graph’s context. In the above\n",
    "example, the operation “add” is the sole node.\n",
    "Edges are the actual values that get passed to and from Operations, and are typically\n",
    "drawn as arrows. In the “add” example, the inputs 1 and 2 are both edges leading into\n",
    "the node, while the output 3 is an edge leading out of the node. Conceptually, we can\n",
    "think of edges as the link between different Operations as they carry information\n",
    "from one node to the next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies\n",
    "The concept of a dependency is straight-forward: any node, A, that is required for the\n",
    "computation of a later node, B, is said to be a dependency of B. If a node A and node B do\n",
    "not need any information from one another, they are said to be independent. To visually\n",
    "represent this, let’s take a look at what happens if the multiplication node c is unable to\n",
    "finish its computation (for whatever reason):\n",
    "![title](img/gb2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building your first TensorFlow graph\n",
    "![title](img/gb3.png)\n",
    "Here’s what it looks like in TensorFlow code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant(5, name=\"input_a\")\n",
    "b = tf.constant(3, name=\"input_b\")\n",
    "c = tf.multiply(a,b, name=\"mul_c\")\n",
    "d = tf.add(a,b, name=\"add_d\")\n",
    "e = tf.add(c,d, name=\"add_e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's try a larger graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/large_graph.png)\n",
    "this is the graph thay we will build "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we’ll need to do, as always, is import the TensorFlow library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#skip this if you have already imported  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re going to explicitly create the graph that we’d like to use instead of using the\n",
    "default graph, so make one with tf.Graph():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope(\"variables\"):\n",
    "        # Variable to keep track of how many times the graph has been run\n",
    "        global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\"global_step\")\n",
    "        # Variable that keeps track of the sum of all output values over time:\n",
    "        total_output = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"total_output\")\n",
    "    with tf.name_scope(\"transformation\"):\n",
    "        # Separate input layer\n",
    "        with tf.name_scope(\"input\"):\n",
    "            # Create input placeholder- takes in a Vector\n",
    "            a = tf.placeholder(tf.float32, shape=[None], name=\"input_placeholder_a\")\n",
    "        # Separate middle layer\n",
    "        with tf.name_scope(\"intermediate_layer\"):\n",
    "            b = tf.reduce_prod(a, name=\"product_b\")\n",
    "            c = tf.reduce_sum(a, name=\"sum_c\")\n",
    "        # Separate output layer\n",
    "        with tf.name_scope(\"output\"):\n",
    "            output = tf.add(b, c, name=\"output\")\n",
    "    with tf.name_scope(\"update\"):\n",
    "        # Increments the total_output Variable by the latest output\n",
    "        update_total = total_output.assign_add(output)\n",
    "        # Increments the above `global_step` Variable, should be run whenever the graph is run\n",
    "        increment_step = global_step.assign_add(1)\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        avg = tf.div(update_total, tf.cast(increment_step, tf.float32), name=\"average\")\n",
    "        tf.summary.scalar('output_summary',output)\n",
    "        tf.summary.scalar('average_summary', avg)\n",
    "        tf.summary.scalar('total_summary',update_total)\n",
    "    with tf.name_scope(\"global_ops\"):\n",
    "        # Initialization Op\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Merge all summaries into one Operation\n",
    "        merged_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "writer =  tf.summary.FileWriter('./summary', graph)\n",
    "sess.run(init)\n",
    "def run_graph(input_tensor):\n",
    "    feed_dict = {a: input_tensor}\n",
    "    _, step, summary = sess.run([output, increment_step, merged_summaries],feed_dict=feed_dict)\n",
    "    writer.add_summary(summary, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_graph([2,8])\n",
    "run_graph([3,1,3,3])\n",
    "run_graph([8])\n",
    "run_graph([1,2,3])\n",
    "run_graph([11,4])\n",
    "run_graph([4,1])\n",
    "run_graph([7,3,1])\n",
    "run_graph([6,3])\n",
    "run_graph([0,2])\n",
    "run_graph([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run command tensorboard --logdir ./summary and access to localhost:6006 to visulize the result \n",
    "it should look like:\n",
    "![title](img/tf1.png)\n",
    "![title](img/tf2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
